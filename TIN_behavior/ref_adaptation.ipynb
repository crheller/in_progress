{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599517740644",
   "display_name": "Python 3.7.4 64-bit ('lbhb': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nems_lbhb.baphy_experiment import BAPHYExperiment\n",
    "import charlieTools.baphy_remote as br\n",
    "import charlieTools.noise_correlations as nc\n",
    "from charlieTools.plotting import compute_ellipse\n",
    "from sklearn.decomposition import PCA\n",
    "import nems.db as nd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCE ONLY summaries\n",
    "* highlight effect of adaption on responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global settings / loading options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording loading options\n",
    "options = {'resp': True, 'pupil': False, 'rasterfs': 10}\n",
    "\n",
    "# hardcode stim onset / offset bins to avoid loading exptevents\n",
    "ref_dur = int(0.3 * options['rasterfs'])\n",
    "onset = int(0.1 * options['rasterfs'])\n",
    "offset = int(0.3 * options['rasterfs'])\n",
    "\n",
    "# fig save path\n",
    "fig_path = '/auto/users/hellerc/code/projects/in_progress/TIN_behavior/dump_figs/'\n",
    "\n",
    "# siteids\n",
    "sites = ['CRD010b']  #['CRD009b', 'CRD010b', 'CRD011c', 'CRD012b', 'CRD013b', 'CRD016c', 'CRD017c', 'CRD018d', 'CRD019b']\n",
    "\n",
    "# zscore for state-space projections?\n",
    "zscore = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop over sites, load data, save in dict of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdict = dict.fromkeys(sites)\n",
    "for site in sites:\n",
    "    if os.path.isdir(os.path.join(fig_path, site)):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(os.path.join(fig_path, site))\n",
    "    \n",
    "    site_path = os.path.join(fig_path, site)\n",
    "    # get parmfiles\n",
    "    sql = \"SELECT sCellFile.cellid, sCellFile.respfile, gDataRaw.resppath from sCellFile INNER JOIN\" \\\n",
    "               \" gCellMaster ON (gCellMaster.id=sCellFile.masterid) INNER JOIN\" \\\n",
    "               \" gDataRaw ON (sCellFile.rawid=gDataRaw.id)\" \\\n",
    "               \" WHERE gCellMaster.siteid=%s\" \\\n",
    "               \" and gDataRaw.runclass='TBP' and gDataRaw.bad=0\"\n",
    "    d = nd.pd_query(sql, (site,))\n",
    "    d['parmfile'] = [f.replace('.spk.mat', '.m') for f in d['respfile']]\n",
    "    parmfiles = np.unique(np.sort([os.path.join(d['resppath'].iloc[i], d['parmfile'].iloc[i]) for i in range(d.shape[0])])).tolist()\n",
    "    manager = BAPHYExperiment(parmfiles)\n",
    "    rec = manager.get_recording(**options)\n",
    "    rec['resp'] = rec['resp'].rasterize()\n",
    "\n",
    "    rdict[site] = rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each site, extract REF responses and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for site in sites:\n",
    "    rec = rdict[site].copy()\n",
    "\n",
    "    # extract / sort ref stim epochs\n",
    "    ref_stims = [x for x in rec['resp'].epochs.name.unique() if 'STIM_' in x]\n",
    "    idx = np.argsort([int(s.split('_')[-1]) for s in ref_stims])\n",
    "    ref_stims = np.array(ref_stims)[idx].tolist()\n",
    "\n",
    "    # PCA on trial averaged ref responses, collapsed over duration\n",
    "    rall = rec.copy()\n",
    "    rall = rall.create_mask(True)\n",
    "    rall = rall.and_mask(['HIT_TRIAL', 'MISS_TRIAL', 'INCORRECT_HIT_TRIAL', 'CORRECT_REJECT_TRIAL', 'PASSIVE_EXPERIMENT'])\n",
    "    # can't simply extract evoked for refs because can be longer/shorted if it came after target \n",
    "    # and / or if it was the last stim.So, masking prestim / postim doesn't work.Do it manually\n",
    "    d = rall['resp'].extract_epochs(ref_stims, mask=rall['mask'])\n",
    "    d = {k: v[~np.isnan(v[:, :, onset:offset].sum(axis=(1, 2))), :, :] for (k, v) in d.items()}\n",
    "    d = {k: v[:, :, onset:offset] for (k, v) in d.items()}\n",
    "\n",
    "    # zscore each neuron, if zscore is true\n",
    "    m = np.concatenate([d[e] for e in d.keys()], axis=0).mean(axis=-1).mean(axis=0)\n",
    "    sd = np.concatenate([d[e] for e in d.keys()], axis=0).mean(axis=-1).std(axis=0)\n",
    "    if zscore:\n",
    "        d = {k: (v.transpose(0, -1, 1) - m).transpose(0, -1, 1)  for (k, v) in d.items()}\n",
    "        d = {k: (v.transpose(0, -1, 1) / sd).transpose(0, -1, 1)  for (k, v) in d.items()}\n",
    "\n",
    "    # do PCA\n",
    "    Rall_u = np.vstack([d[k].sum(axis=2).mean(axis=0) for k in d.keys()])\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(Rall_u)\n",
    "    pc_axes = pca.components_\n",
    "\n",
    "    # define ACTIVE / PASSIVE response dictionaries. Divide into trial onset / not trial onset data\n",
    "    ra = rec.copy().create_mask(True)\n",
    "    ra = ra.and_mask(['HIT_TRIAL', 'MISS_TRIAL', 'CORRECT_REJECT_TRIAL', 'INCORRECT_HIT_TRIAL'])\n",
    "    aTrial_onsets = ra['resp'].get_epoch_indices('TRIAL', mask=ra['mask'])[:, 0]\n",
    "    aEpoch_onsets = {k: ra['resp'].get_epoch_indices(k, mask=ra['mask'])[:, 0] for k in ref_stims}\n",
    "    onset_mask = {k: np.array([True if o in aTrial_onsets else False for o in aEpoch_onsets[k]]) for k in aEpoch_onsets.keys()}\n",
    "    da = ra['resp'].extract_epochs(ref_stims, mask=ra['mask'])\n",
    "    da = {k: v[:, :, onset:offset] for (k, v) in da.items()}\n",
    "    onset_mask = {k: onset_mask[k][~np.isnan(da[k].sum(axis=(1, 2)))] for k in onset_mask.keys()}\n",
    "    da = {k: v[~np.isnan(v.sum(axis=(1, 2))), :, :] for (k, v) in da.items()}\n",
    "    if zscore:\n",
    "        da = {k: (v.transpose(0, -1, 1) - m).transpose(0, -1, 1)  for (k, v) in da.items()}\n",
    "        da = {k: (v.transpose(0, -1, 1) / sd).transpose(0, -1, 1)  for (k, v) in da.items()}\n",
    "    \n",
    "    da_onsets = {k: v[onset_mask[k], :, :] for k, v in da.items()}\n",
    "    da = {k: v[~onset_mask[k], :, :] for k, v in da.items()}\n",
    "\n",
    "    da_spont = ra['resp'].extract_epochs('PreStimSilence', mask=ra['mask'])\n",
    "    da_spont = {k: v[~np.isnan(v.sum(axis=(1, 2))), :, :] for (k, v) in da_spont.items()}\n",
    "\n",
    "    rp = rec.copy().create_mask(True)\n",
    "    rp = rp.and_mask(['PASSIVE_EXPERIMENT'])\n",
    "    pTrial_onsets = ra['resp'].get_epoch_indices('TRIAL', mask=rp['mask'])[:, 0]\n",
    "    pEpoch_onsets = {k: rp['resp'].get_epoch_indices(k, mask=rp['mask'])[:, 0] for k in ref_stims}\n",
    "    onset_mask = {k: np.array([True if o in pTrial_onsets else False for o in pEpoch_onsets[k]]) for k in pEpoch_onsets.keys()}\n",
    "    dp = rp['resp'].extract_epochs(ref_stims, mask=rp['mask'])\n",
    "    dp = {k: v[:, :, onset:offset] for (k, v) in dp.items()}\n",
    "    onset_mask = {k: onset_mask[k][~np.isnan(dp[k].sum(axis=(1, 2)))] for k in onset_mask.keys()}\n",
    "    dp = {k: v[~np.isnan(v.sum(axis=(1, 2))), :, :] for (k, v) in dp.items()}\n",
    "    if zscore:\n",
    "        dp = {k: (v.transpose(0, -1, 1) - m).transpose(0, -1, 1)  for (k, v) in dp.items()}\n",
    "        dp = {k: (v.transpose(0, -1, 1) / sd).transpose(0, -1, 1)  for (k, v) in dp.items()}\n",
    "    \n",
    "    dp_onsets = {k: v[onset_mask[k], :, :] for k, v in dp.items()}\n",
    "    dp = {k: v[~onset_mask[k], :, :] for k, v in dp.items()}\n",
    "\n",
    "    dp_spont = rp['resp'].extract_epochs('PreStimSilence', mask=rp['mask'])\n",
    "    dp_spont = {k: v[~np.isnan(v.sum(axis=(1, 2))), :, :] for (k, v) in dp_spont.items()}\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    colors = plt.cm.get_cmap('viridis', len(ref_stims))\n",
    "    col = 0\n",
    "    # plot each epoch. Check indices of each single trial to see if it coincided with trial starts\n",
    "    trial_onsets = rec['resp'].get_epoch_indices('TRIAL')[:, 0]\n",
    "    for e in ref_stims:\n",
    "        try:\n",
    "            passive = dp[e].mean(axis=-1).dot(pc_axes.T)\n",
    "            ax[0].plot(passive[:, 0], passive[:, 1], alpha=0.3, marker='.', lw=0, color=colors(col))\n",
    "            el = compute_ellipse(passive[:, 0], passive[:, 1])\n",
    "            ax[0].plot(el[0], el[1], lw=1, color=ax[0].get_lines()[-1].get_color())\n",
    "\n",
    "            try:\n",
    "                passive = dp_onsets[e].mean(axis=-1).dot(pc_axes.T)\n",
    "                ax[0].plot(passive[:, 0], passive[:, 1], alpha=1, marker='o', \n",
    "                            markeredgecolor='k', markeredgewidth=1,\n",
    "                            lw=0, color=colors(col))\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            active = da[e].mean(axis=-1).dot(pc_axes.T)\n",
    "            ax[1].plot(active[:, 0], active[:, 1], alpha=0.3, marker='.', lw=0, color=colors(col))\n",
    "            el = compute_ellipse(active[:, 0], active[:, 1])\n",
    "            ax[1].plot(el[0], el[1], lw=1, color=ax[1].get_lines()[-1].get_color())\n",
    "\n",
    "            try:\n",
    "                active = da_onsets[e].mean(axis=-1).dot(pc_axes.T)\n",
    "                ax[1].plot(active[:, 0], active[:, 1], alpha=1, marker='o', \n",
    "                        markeredgecolor='k', markeredgewidth=1,\n",
    "                        lw=0, color=colors(col))\n",
    "            except:\n",
    "                pass\n",
    "        except: \n",
    "            pass\n",
    "        col += 1\n",
    "\n",
    "    # plot the spont distributions\n",
    "    passive = dp_spont['PreStimSilence'].mean(axis=-1).dot(pc_axes.T)\n",
    "    active = da_spont['PreStimSilence'].mean(axis=-1).dot(pc_axes.T)\n",
    "\n",
    "    ax[0].plot(passive[:, 0], passive[:, 1], alpha=0.3, marker='.', lw=0, color='lightgrey')\n",
    "    el = compute_ellipse(passive[:, 0], passive[:, 1])\n",
    "    ax[0].plot(el[0], el[1], lw=2, color='k')\n",
    "\n",
    "    ax[1].plot(active[:, 0], active[:, 1], alpha=0.3, marker='.', lw=0, color='lightgrey')\n",
    "    el = compute_ellipse(active[:, 0], active[:, 1])\n",
    "    ax[1].plot(el[0], el[1], lw=2, color='k')\n",
    "\n",
    "    ax[0].axhline(0, linestyle='--', lw=2, color='grey')\n",
    "    ax[0].axvline(0, linestyle='--', lw=2, color='grey')\n",
    "    ax[1].axhline(0, linestyle='--', lw=2, color='grey')\n",
    "    ax[1].axvline(0, linestyle='--', lw=2, color='grey')\n",
    "\n",
    "    ax[0].set_title('Passive')\n",
    "    ax[1].set_title('Active')\n",
    "    ax[0].set_xlabel(r'$PC_1$ (var. explained: {})'.format(round(pca.explained_variance_ratio_[0], 3)))\n",
    "    ax[1].set_xlabel(r'$PC_1$ (var. explained: {})'.format(round(pca.explained_variance_ratio_[0], 3)))\n",
    "    ax[0].set_ylabel(r'$PC_2$ (var. explained: {})'.format(round(pca.explained_variance_ratio_[1], 3)))\n",
    "    ax[1].set_ylabel(r'$PC_2$ (var. explained: {})'.format(round(pca.explained_variance_ratio_[1], 3)))\n",
    "\n",
    "    ax[0].legend(frameon=False, fontsize=6)\n",
    "\n",
    "    fig.canvas.set_window_title(\"PCA decompostion\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(site_path + '/PCA_space.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_spont['PreStimSilence'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    passive = dp_spont['PreStimSilence'].mean(axis=-1).dot(pc_axes.T)\n",
    "    active = da_spont['PreStimSilence'].mean(axis=-1).dot(pc_axes.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}